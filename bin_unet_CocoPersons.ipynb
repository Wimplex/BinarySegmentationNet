{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bin_unet_CocoPersons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRgfD7a-OeIz",
        "colab_type": "code",
        "outputId": "271c3d08-5d1b-4a92-b722-0ed9054521d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf60DThOvNc1",
        "colab_type": "text"
      },
      "source": [
        "### Импорты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_dD2Q_uvD27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage.color import gray2rgb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function, Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHLIJLmd92SQ",
        "colab_type": "text"
      },
      "source": [
        "### Утилитарные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJCVsHeA91m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# В PyTorch отсутствует общепринятая функция округления\n",
        "def round_tensor(tensor, digits):\n",
        "    return (tensor * 10 ** digits).round() / (10 ** digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nTY6wg80WG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Наложение маски на изображение\n",
        "def put_mask(image, mask):\n",
        "    image[:,:,0][mask == 1] = 255\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgryWFtJ-1rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция загрузки модели из облака\n",
        "def download_model(name):\n",
        "    files.download(name + '.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W0c7GLEvrme",
        "colab_type": "text"
      },
      "source": [
        "### Конфигурация обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoggkHmsvvJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    __options = [\n",
        "        # Для обучения\n",
        "        {'batch_size': 16, 'lr': 2e-3, 'n_epochs': 10, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "        {'batch_size': 16, 'lr': 2e-3, 'n_epochs': 500, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "\n",
        "        # Для тестирования\n",
        "        {'batch_size': 8},\n",
        "    ]\n",
        "\n",
        "    # Данные об изображениях\n",
        "    WIDTH = 224\n",
        "    HEIGHT = 224\n",
        "\n",
        "    # Пути, использущиеся в работе\n",
        "    # DATA_DIR = \"drive/My Drive/CocoMiniPersonsData\"\n",
        "    DATA_DIR = \"drive/My Drive/Colab Notebooks/CocoMiniPersonsData\"\n",
        "    OUTPUT_DIR = \"output/\"\n",
        "    TRAIN_OUTPUT = \"train_output/\"\n",
        "\n",
        "    # Классы объектов датасета\n",
        "    NUM_CLASSES = 2\n",
        "    TRAIN_CLASS_PROBS = torch.Tensor([0.92439456, 0.07560544])\n",
        "    TEST_CLASS_PROBS = torch.Tensor([0.91990379, 0.08009621])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_option(idx):\n",
        "        return Config.__options[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhcHMfQh1rii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    os.mkdir(Config.OUTPUT_DIR)\n",
        "    os.mkdir(Config.TRAIN_OUTPUT)\n",
        "    os.mkdir('temp/')\n",
        "except FileExistsError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bjK77mVvQCO",
        "colab_type": "text"
      },
      "source": [
        "### Функции бинаризации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK-9VI57vMgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция бинаризации входа. \n",
        "# На выходе дает либо 1, либо -1\n",
        "class BinarizeF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(cxt, input):\n",
        "        output = input.new(input.size())\n",
        "        output[input >= 0] = 1\n",
        "        output[input < 0] = -1\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(cxt, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "binarize = BinarizeF.apply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DJs6rDvYqt",
        "colab_type": "text"
      },
      "source": [
        "### Бинаризованные модули"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-39zSKPvV1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryTanh(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryTanh, self).__init__()\n",
        "        self.hardtanh = nn.Hardtanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.hardtanh(x)\n",
        "        output = binarize(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class BinaryLinear(nn.Linear):\n",
        "    def forward(self, x):\n",
        "        binary_weight = binarize(self.weight)\n",
        "        if self.bias is None:\n",
        "            return F.linear(x, binary_weight)\n",
        "        else:\n",
        "            return F.linear(x, binary_weight, self.bias)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Glorot-инициализация\n",
        "        in_features, out_features = self.weight.size()\n",
        "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "        self.weight.lr_scale = 1. / stdv\n",
        "\n",
        "\n",
        "class BinaryConv2d(nn.Conv2d):\n",
        "    def forward(self, x):\n",
        "        bw = binarize(self.weight)\n",
        "        return F.conv2d(x, bw, self.bias, self.stride,\n",
        "                               self.padding, self.dilation, self.groups)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Glorot-инициализация\n",
        "        in_features = self.in_channels\n",
        "        out_features = self.out_channels\n",
        "        for k in self.kernel_size:\n",
        "            in_features *= k\n",
        "            out_features *= k\n",
        "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "        self.weight.lr_scale = 1. / stdv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG8Pp12r1p6N",
        "colab_type": "text"
      },
      "source": [
        "### Функция потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6rsjQpy1srX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_loss(pred, target, smooth=.3):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()\n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    numerator = (2. * intersection + smooth)\n",
        "    denominator = (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth) \n",
        "    loss = 1 - numerator / denominator\n",
        "    return loss.mean() \n",
        "\n",
        "def calculate_loss(pred, target, class_weights, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target, pos_weight=class_weights[1])\n",
        "    pred = F.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G735kkI6vf_X",
        "colab_type": "text"
      },
      "source": [
        "### UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o0ShzJ3wYkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleConvUnit(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, binary=-1):\n",
        "        super(DoubleConvUnit, self).__init__()\n",
        "\n",
        "        if binary == -1:\n",
        "            self.unit = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        elif binary == 0:\n",
        "            self.unit = nn.Sequential(\n",
        "                BinaryConv2d(in_channels, out_channels, 3, padding=1),\n",
        "                BinaryTanh(),\n",
        "                Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        elif binary == 1:\n",
        "            self.unit = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                BinaryConv2d(out_channels, out_channels, 3, padding=1),\n",
        "                BinaryTanh(),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.unit(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xupwN0_gvddp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channels, n_classes, name='unet'):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.input_channels = input_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.name = name\n",
        "        self.device = 'cuda:0'\n",
        "\n",
        "        self.down_1 = DoubleConvUnit(3, 64)\n",
        "        self.down_2 = DoubleConvUnit(64, 128, binary=0)\n",
        "        self.down_3 = DoubleConvUnit(128, 256, binary=0)\n",
        "        self.down_4 = DoubleConvUnit(256, 512, binary=0)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.up_3 = DoubleConvUnit(512 + 256, 256, binary=1)\n",
        "        self.up_2 = DoubleConvUnit(256 + 128, 128, binary=1)\n",
        "        self.up_1 = DoubleConvUnit(128 + 64, 64, binary=1)\n",
        "\n",
        "        self.output_conv = nn.Conv2d(64, n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.down_1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.down_2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.down_3(x)\n",
        "        x = self.maxpool(conv3)\n",
        "\n",
        "        x = self.down_4(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.up_3(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.up_2(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "\n",
        "        x = self.up_1(x)\n",
        "        \n",
        "        out = self.output_conv(x)\n",
        "        out = F.softmax(out, dim=1)\n",
        "        return out\n",
        "\n",
        "    def load(self, path):\n",
        "        self.to(self.device)\n",
        "        self.load_state_dict(torch.load(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoxmUgYrvk3m",
        "colab_type": "text"
      },
      "source": [
        "### Функции выполнения модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kX-Crxt0hV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_results(softmaxed, image_batch, mask_batch, path, name):\n",
        "    for idx, predicted_mask in enumerate(softmaxed):\n",
        "            input_image = image_batch[idx].detach().cpu().numpy()\n",
        "            input_image = input_image.transpose((1, 2, 0))\n",
        "            target_mask = mask_batch[idx].detach().cpu().numpy()\n",
        "            pr_mask = predicted_mask.detach().cpu().numpy().argmax(axis=0)\n",
        "\n",
        "            fig = plt.figure()\n",
        "\n",
        "            plot = fig.add_subplot(1, 2, 1)\n",
        "            with_mask = put_mask(input_image.copy(), pr_mask)\n",
        "            plt.imshow(with_mask)\n",
        "            plot.set_title(\"Predicted\")\n",
        "\n",
        "            plot = fig.add_subplot(1, 2, 2)\n",
        "            with_mask = put_mask(input_image.copy(), target_mask)\n",
        "            plt.imshow(with_mask)\n",
        "            plot.set_title(\"Ground truth\")\n",
        "\n",
        "            fig.savefig(os.path.join(path, name + f'_id:{idx}.png'))\n",
        "            plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxHpOMNdvoiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, data_loader, n_epochs, lr, class_weights, verbose=0):\n",
        "    net.to(net.device)\n",
        "\n",
        "    print(net.device)\n",
        "\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "    class_weights = 1.0 / class_weights\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=class_weights).to(net.device)\n",
        "\n",
        "    training_time = time.time()\n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_time = time.time()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        processed = 0\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            image_batch = Variable(X_batch).to(net.device)\n",
        "            mask_batch = Variable(y_batch).to(net.device)\n",
        "\n",
        "            output_batch = net(image_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = calculate_loss(output_batch, mask_batch.unsqueeze(1), class_weights=class_weights)\n",
        "            # loss = loss_fn(output_batch, mask_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.float()\n",
        "            processed += data_loader.batch_size\n",
        "            processed_percent = round(\n",
        "                100.0 * processed / (len(data_loader) * data_loader.batch_size), \n",
        "                ndigits=3\n",
        "            )\n",
        "            if verbose == 2:\n",
        "                print(f\"Эпоха {epoch}: {processed_percent}%,\"\n",
        "                    f\"loss: {round_tensor(train_loss / processed, 5)}\")\n",
        "                \n",
        "        # Вывод результатов эпохи\n",
        "        epoch_time = time.time() - epoch_time\n",
        "        if verbose:\n",
        "            print(f\"Окончание эпохи. Эпоха: {epoch}, \"\n",
        "                  f\"train_loss: {round_tensor(train_loss / processed, 5)}; {epoch_time} сек.; \"\n",
        "                  f\"Сохранение...\")\n",
        "        \n",
        "        # Сохраняем модель по окончанию эпохи\n",
        "        with open(f'{net.name}.pth', 'w'):\n",
        "            torch.save(net.state_dict(), f\"{net.name}.pth\")\n",
        "        download_model(net.name)\n",
        "\n",
        "    print(f\"Время обучения: {time.time() - training_time} сек.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H1RYwbbwkLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, data_loader, class_weights):\n",
        "    with torch.no_grad():\n",
        "        loss_func = nn.CrossEntropyLoss(1.0 / class_weights).to(net.device)\n",
        "\n",
        "        batch_id = 0\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            image_batch = Variable(X_batch).to(net.device)\n",
        "            mask_batch = Variable(y_batch).to(net.device)\n",
        "\n",
        "            softmaxed = net(image_batch)\n",
        "            loss = loss_func(softmaxed, mask_batch)\n",
        "\n",
        "            save_results(softmaxed, image_batch, mask_batch, \n",
        "                        path=Config.OUTPUT_DIR, name=f'batch:{batch_id}')\n",
        "            \n",
        "            batch_id += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QUGuprWvpW0",
        "colab_type": "text"
      },
      "source": [
        "### Набор данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2RWX18Cv8Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CocoPersons_Segmentation(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset_dir, train=True):\n",
        "        super(CocoPersons_Segmentation, self).__init__()\n",
        "\n",
        "        set_ = 'train/' if train else 'test/'\n",
        "        self.images_dir = os.path.join(dataset_dir, set_ , 'images/')\n",
        "        self.masks_dir = os.path.join(dataset_dir, set_, 'masks/')\n",
        "\n",
        "        self.masks_files = os.listdir(self.masks_dir)\n",
        "        self.file_names = [mask.split('_')[-1].split('.')[0] for mask in self.masks_files if mask.endswith('.png')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.file_names[idx]\n",
        "        mask_path = os.path.join(self.masks_dir, 'seg_' + name + '.png')\n",
        "        image_path = os.path.join(self.images_dir, name + '.jpg')\n",
        "\n",
        "        image = torch.FloatTensor(self.__load_image(image_path))\n",
        "        mask = torch.LongTensor(self.__load_mask(mask_path))\n",
        "        return image, mask\n",
        "\n",
        "    def __load_image(self, path):\n",
        "        img = np.array(Image.open(path).resize((Config.WIDTH, Config.HEIGHT)))\n",
        "\n",
        "        try:\n",
        "            image = img.transpose((2, 0, 1))\n",
        "        except ValueError:\n",
        "            image = gray2rgb(img).transpose((2, 0, 1))\n",
        "\n",
        "        image = np.array(image, dtype=np.float32) / 255.0\n",
        "        return image\n",
        "\n",
        "    def __load_mask(self, path):\n",
        "        mask = Image.open(path).resize((Config.WIDTH, Config.HEIGHT))\n",
        "        mask = np.array(mask, dtype=np.uint8) / 255.0\n",
        "        return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoBhHqTwFtk",
        "colab_type": "text"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVD1yWPPz5GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Выбираем параметры обучения\n",
        "train_options = Config.get_option(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLYbRG71zoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Создаем объект-DataLoader на тренировочных данных\n",
        "coco_train_set = CocoPersons_Segmentation(dataset_dir=Config.DATA_DIR, train=True)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    coco_train_set,\n",
        "    batch_size=train_options['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtIrNnuOwLJg",
        "colab_type": "code",
        "outputId": "00d2ee24-1e68-4a8e-9d55-c3b577b86dda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Создаем и строим модель\n",
        "model = UNet(input_channels=3, n_classes=Config.NUM_CLASSES, name='unet0')\n",
        "\n",
        "# Запускаем обучение модели\n",
        "train(\n",
        "    model, \n",
        "    data_loader=train_loader,\n",
        "    n_epochs=train_options['n_epochs'],\n",
        "    lr=train_options['lr'],\n",
        "    class_weights=Config.TRAIN_CLASS_PROBS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d680c7cdcfc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unet0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Запускаем обучение модели\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train(\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-6fa8b0a3b211>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_channels, n_classes, name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleConvUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleConvUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleConvUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoubleConvUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-0dc112f99a62>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, binary)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mBinaryConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mBinaryTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Conv2d' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4wy_KyxlgMW",
        "colab_type": "text"
      },
      "source": [
        "### Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpupcRxA1xMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Делаем похожие шаги\n",
        "test_options = Config.get_option(-1)\n",
        "\n",
        "coco_test_set = CocoPersons_Segmentation(dataset_dir=Config.DATA_DIR, train=False)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    coco_test_set,\n",
        "    batch_size=test_options['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kU73Qpi18u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загружаем обученную модель\n",
        "model = UNet(input_channels=3, n_classes=Config.NUM_CLASSES)\n",
        "model.load('unet0.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAx4RjQbUyRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Строим предсказание на тестовых данных\n",
        "predict(\n",
        "    model,\n",
        "    test_loader,\n",
        "    class_weights=Config.TEST_CLASS_PROBS\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}