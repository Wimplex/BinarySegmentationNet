{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bin_segnet_CocoPersons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf60DThOvNc1",
        "colab_type": "text"
      },
      "source": [
        "### Импорты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_dD2Q_uvD27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage.color import gray2rgb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function, Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHLIJLmd92SQ",
        "colab_type": "text"
      },
      "source": [
        "### Утилитарные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJCVsHeA91m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# В PyTorch отсутствует общепринятая функция округления\n",
        "def round_tensor(tensor, digits):\n",
        "    return (tensor * 10 ** digits).round() / (10 ** digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nTY6wg80WG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Наложение маски на изображение\n",
        "def put_mask(image, mask):\n",
        "    image[:,:,0][mask == 1] = 255\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W0c7GLEvrme",
        "colab_type": "text"
      },
      "source": [
        "### Конфигурация обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoggkHmsvvJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "    __options = [\n",
        "        # Для тренировки\n",
        "        {'batch_size': 128, 'lr': 5e-3, 'n_epochs': 40, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "        {'batch_size': 64, 'lr': 2e-3, 'n_epochs': 20, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "        {'batch_size': 16, 'lr': 2e-3, 'n_epochs': 10, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "        {'batch_size': 16, 'lr': 2e-3, 'n_epochs': 500, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "        {'batch_size': 32, 'lr': 2e-3, 'n_epochs': 25, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "        {'batch_size': 64, 'lr': 5e-3, 'n_epochs': 30, 'momentum': 1e-5, 'eps': 1e-5},\n",
        "\n",
        "        # Для тестирования\n",
        "        {'batch_size': 8},\n",
        "    ]\n",
        "\n",
        "    # Данные об изображениях\n",
        "    WIDTH = 224\n",
        "    HEIGHT = 224\n",
        "\n",
        "    # Пути, использущиеся в работе\n",
        "    DATA_DIR = \"drive/My Drive/Colab Notebooks/CocoMiniPersonsData\"\n",
        "    OUTPUT_DIR = \"output/\"\n",
        "    TRAIN_OUTPUT = \"train_output/\"\n",
        "\n",
        "    # Классы объектов датасета\n",
        "    NUM_CLASSES = 2\n",
        "    TRAIN_CLASS_PROBS = torch.Tensor([0.92439456, 0.07560544])\n",
        "    TEST_CLASS_PROBS = torch.Tensor([0.91990379, 0.08009621])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_option(idx):\n",
        "        return Config.__options[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhcHMfQh1rii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Создание директорий, необходимых при обучении и тестировании\n",
        "try:\n",
        "    os.mkdir(Config.OUTPUT_DIR)\n",
        "    os.mkdir(Config.TRAIN_OUTPUT)\n",
        "    os.mkdir('temp/')\n",
        "except FileExistsError:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bjK77mVvQCO",
        "colab_type": "text"
      },
      "source": [
        "### Функция бинаризации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK-9VI57vMgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция бинаризации входа. На выходе дает либо 1, либо -1.\n",
        "# Определена на этапах и прямого, и обратного распространения.\n",
        "class BinarizeF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(cxt, input):\n",
        "        output = input.new(input.size())\n",
        "        output[input >= 0] = 1\n",
        "        output[input < 0] = -1\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(cxt, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return grad_input\n",
        "\n",
        "\n",
        "binarize = BinarizeF.apply"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DJs6rDvYqt",
        "colab_type": "text"
      },
      "source": [
        "### Бинаризованные модули"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-39zSKPvV1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ниже представлены бинарные варианты стандартных объектов слоев и активаций\n",
        "\n",
        "# Бинарный вариант функции активации гиперболического тангенса\n",
        "class BinaryTanh(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryTanh, self).__init__()\n",
        "        self.hardtanh = nn.Hardtanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.hardtanh(x)\n",
        "        output = binarize(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Полносвязный слой с бинарными весами на этапе прямого распространения\n",
        "class BinaryLinear(nn.Linear):\n",
        "    def forward(self, x):\n",
        "        binary_weight = binarize(self.weight)\n",
        "        if self.bias is None:\n",
        "            return F.linear(x, binary_weight)\n",
        "        else:\n",
        "            return F.linear(x, binary_weight, self.bias)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Glorot-инициализация\n",
        "        in_features, out_features = self.weight.size()\n",
        "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "        self.weight.lr_scale = 1. / stdv\n",
        "\n",
        "\n",
        "# Сверточный слой с бинарными весами на этапе прямого распространения\n",
        "class BinaryConv2d(nn.Conv2d):\n",
        "    def forward(self, x):\n",
        "        bw = binarize(self.weight)\n",
        "        return F.conv2d(x, bw, self.bias, self.stride,\n",
        "                               self.padding, self.dilation, self.groups)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Glorot-инициализация\n",
        "        in_features = self.in_channels\n",
        "        out_features = self.out_channels\n",
        "        for k in self.kernel_size:\n",
        "            in_features *= k\n",
        "            out_features *= k\n",
        "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "        self.weight.lr_scale = 1. / stdv\n",
        "\n",
        "\n",
        "# Сверточный транспозиционный слой с бинарными весами на этапе прямого распространения\n",
        "class BinaryConvTranspose2d(nn.ConvTranspose2d):\n",
        "    def forward(self, x):\n",
        "        bw = binarize(self.weight)\n",
        "        return F.conv_transpose2d(x, bw, self.bias, self.stride, self.padding,\n",
        "                                  self.output_padding, self.groups, self.dilation)\n",
        "        \n",
        "    def reset_parameters(self):\n",
        "        # Glorot-инициализация\n",
        "        in_features = self.in_channels\n",
        "        out_features = self.out_channels\n",
        "        for k in self.kernel_size:\n",
        "            in_features *= k\n",
        "            out_features *= k\n",
        "        stdv = math.sqrt(1.5 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.zero_()\n",
        "\n",
        "        self.weight.lr_scale = 1. / stdv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G735kkI6vf_X",
        "colab_type": "text"
      },
      "source": [
        "### SegNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o0ShzJ3wYkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Блок понижающего отбора\n",
        "class SegnetDownsampleUnit(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, binary=False):\n",
        "        super(SegnetDownsampleUnit, self).__init__()\n",
        "\n",
        "        if binary:\n",
        "            self.conv = BinaryConv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "            self.activation = BinaryTanh()\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "            self.activation = nn.ReLU()\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Блок повышающего отбора\n",
        "class SegnetUpsampleUnit(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, binary=False, use_bn=True):\n",
        "        super(SegnetUpsampleUnit, self).__init__()\n",
        "\n",
        "        if binary:\n",
        "            self.conv_tr = BinaryConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "            self.activation = BinaryTanh()\n",
        "        else:\n",
        "            self.conv_tr = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "            self.activation = nn.ReLU()\n",
        "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_tr(x)\n",
        "\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xupwN0_gvddp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Реализация архитектуры SegNet с бинарными слоями в составе.\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels, name='segnet'):\n",
        "        super(SegNet, self).__init__()\n",
        "\n",
        "        self.input_channels = input_channels\n",
        "        self.output_channels = output_channels\n",
        "        self.name = name\n",
        "        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        exp_fact = 2\n",
        "        init_layers = 32\n",
        "\n",
        "        self.ds_00 = SegnetDownsampleUnit(self.input_channels, init_layers)\n",
        "        self.ds_01 = SegnetDownsampleUnit(init_layers, init_layers)\n",
        "\n",
        "        self.ds_10 = SegnetDownsampleUnit(init_layers, init_layers * exp_fact)\n",
        "        self.ds_11 = SegnetDownsampleUnit(init_layers * exp_fact, init_layers * exp_fact, binary=True)\n",
        "\n",
        "        self.ds_20 = SegnetDownsampleUnit(init_layers * exp_fact, init_layers * exp_fact * 2)\n",
        "        self.ds_21 = SegnetDownsampleUnit(init_layers * exp_fact * 2, init_layers * exp_fact * 2)\n",
        "        self.ds_22 = SegnetDownsampleUnit(init_layers * exp_fact * 2, init_layers * exp_fact * 2, binary=True)\n",
        "\n",
        "        self.ds_30 = SegnetDownsampleUnit(init_layers * exp_fact * 2, init_layers * exp_fact * 4)\n",
        "        self.ds_31 = SegnetDownsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        self.ds_32 = SegnetDownsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "\n",
        "        self.ds_40 = SegnetDownsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4)\n",
        "        self.ds_41 = SegnetDownsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        self.ds_42 = SegnetDownsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        \n",
        "        self.us_42 = SegnetUpsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        self.us_41 = SegnetUpsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        self.us_40 = SegnetUpsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4)\n",
        "\n",
        "        self.us_32 = SegnetUpsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        self.us_31 = SegnetUpsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 4, binary=True)\n",
        "        self.us_30 = SegnetUpsampleUnit(init_layers * exp_fact * 4, init_layers * exp_fact * 2)\n",
        "\n",
        "        self.us_22 = SegnetUpsampleUnit(init_layers * exp_fact * 2, init_layers * exp_fact * 2, binary=True)\n",
        "        self.us_21 = SegnetUpsampleUnit(init_layers * exp_fact * 2, init_layers * exp_fact * 2)\n",
        "        self.us_20 = SegnetUpsampleUnit(init_layers * exp_fact * 2, init_layers * exp_fact)\n",
        "\n",
        "        self.us_11 = SegnetUpsampleUnit(init_layers * exp_fact, init_layers * exp_fact)\n",
        "        self.us_10 = SegnetUpsampleUnit(init_layers * exp_fact, init_layers)\n",
        "\n",
        "        self.us_01 = SegnetUpsampleUnit(init_layers, init_layers)\n",
        "        self.us_00 = SegnetUpsampleUnit(init_layers, output_channels, use_bn=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Энкодер\n",
        "\n",
        "        dim_0 = x.shape\n",
        "\n",
        "        x = self.ds_00(x)\n",
        "        x = self.ds_01(x)\n",
        "        x, indices_0 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        dim_1 = x.shape\n",
        "\n",
        "        x = self.ds_10(x)\n",
        "        x = self.ds_11(x)\n",
        "        x, indices_1 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        dim_2 = x.shape\n",
        "\n",
        "        x = self.ds_20(x)\n",
        "        x = self.ds_21(x)\n",
        "        x = self.ds_22(x)\n",
        "        x, indices_2 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        dim_3 = x.shape\n",
        "\n",
        "        x = self.ds_30(x)\n",
        "        x = self.ds_31(x)\n",
        "        x = self.ds_32(x)\n",
        "        x, indices_3 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        dim_4 = x.shape\n",
        "\n",
        "        x = self.ds_40(x)\n",
        "        x = self.ds_41(x)\n",
        "        x = self.ds_42(x)\n",
        "        x, indices_4 = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
        "        dim_d = x.shape\n",
        "        \n",
        "        # Декодер\n",
        "        x = F.max_unpool2d(x, indices_4, kernel_size=2, stride=2, output_size=dim_4)\n",
        "        x = self.us_42(x)\n",
        "        x = self.us_41(x)\n",
        "        x = self.us_40(x)\n",
        "        dim_d4 = x.shape\n",
        "\n",
        "        x = F.max_unpool2d(x, indices_3, kernel_size=2, stride=2, output_size=dim_3)\n",
        "        x = self.us_32(x)\n",
        "        x = self.us_31(x)\n",
        "        x = self.us_30(x)\n",
        "        dim_d3 = x.shape\n",
        "\n",
        "        x = F.max_unpool2d(x, indices_2, kernel_size=2, stride=2, output_size=dim_2)\n",
        "        x = self.us_22(x)\n",
        "        x = self.us_21(x)\n",
        "        x = self.us_20(x)\n",
        "        dim_d2 = x.shape\n",
        "\n",
        "        x = F.max_unpool2d(x, indices_1, kernel_size=2, stride=2, output_size=dim_1)\n",
        "        x = self.us_11(x)\n",
        "        x = self.us_10(x)\n",
        "        dim_d1 = x.shape\n",
        "\n",
        "        x = F.max_unpool2d(x, indices_0, kernel_size=2, stride=2, output_size=dim_0)\n",
        "        x = self.us_01(x)\n",
        "        x = self.us_00(x)\n",
        "\n",
        "        x_softmax = F.softmax(x, dim=1)\n",
        "        return x, x_softmax\n",
        "\n",
        "    # Функция загрузки модели из файла\n",
        "    def load(self, path):\n",
        "        self.to(self.device)\n",
        "        self.load_state_dict(torch.load(path, map_location=self.device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dENSE6rcS8FE",
        "colab_type": "text"
      },
      "source": [
        "### Функции оценки качества модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIILCZ4eTCED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pixel_accuracy(true, pred):\n",
        "    def __pix_acc(mask_true, mask_pred):\n",
        "        return np.sum(mask_true[mask_true == mask_pred])\n",
        "\n",
        "    true = true.detach().cpu().numpy()\n",
        "    pred = pred.detach().cpu().numpy()\n",
        "    accs = []\n",
        "    batch_size = true.shape[0]\n",
        "    for i in range(batch_size):\n",
        "        accs.append(__pix_acc(true[i], pred[i]))\n",
        "    return np.sum(accs) / (batch_size * true.shape[1] * true.shape[2])\n",
        "\n",
        "\n",
        "def dice_coefficient(true, pred):\n",
        "    eps = 1e-6\n",
        "\n",
        "    def __pix_rates(mask_true, mask_pred):\n",
        "        tp = np.sum(mask_pred[mask_pred == mask_true] == 1) / mask_pred.size\n",
        "        fp = np.sum(mask_pred[mask_pred != mask_true] == 1) / mask_pred.size\n",
        "        fn = np.sum(mask_true[mask_true != mask_pred] == 1) / mask_pred.size\n",
        "        return tp, fp, fn\n",
        "\n",
        "    true = true.detach().cpu().numpy()\n",
        "    pred = pred.detach().cpu().numpy()\n",
        "    dices = []\n",
        "    batch_size = true.shape[0]\n",
        "    for i in range(batch_size):\n",
        "        tp, fp, fn = __pix_rates(true[i], pred[i])\n",
        "        dice = (2 * tp) / (2 * tp + fp + fn)\n",
        "        dices.append(dice)\n",
        "\n",
        "    return np.sum(dices) / len(dices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoxmUgYrvk3m",
        "colab_type": "text"
      },
      "source": [
        "### Функции выполнения модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kX-Crxt0hV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция сохранения изображений с результатами работы модели\n",
        "def save_results(softmaxed, image_batch, mask_batch, path, name):\n",
        "    for idx, predicted_mask in enumerate(softmaxed):\n",
        "            input_image = image_batch[idx].detach().cpu().numpy()\n",
        "            input_image = input_image.transpose((1, 2, 0))\n",
        "            target_mask = mask_batch[idx].detach().cpu().numpy()\n",
        "            pr_mask = predicted_mask.detach().cpu().numpy().argmax(axis=0)\n",
        "\n",
        "            fig = plt.figure()\n",
        "\n",
        "            plot = fig.add_subplot(1, 2, 1)\n",
        "            with_mask = put_mask(input_image.copy(), pr_mask)\n",
        "            plt.imshow(with_mask)\n",
        "            plot.set_title(\"Predicted\")\n",
        "\n",
        "            plot = fig.add_subplot(1, 2, 2)\n",
        "            with_mask = put_mask(input_image.copy(), target_mask)\n",
        "            plt.imshow(with_mask)\n",
        "            plot.set_title(\"Ground truth\")\n",
        "\n",
        "            fig.savefig(os.path.join(path, name + f'_id:{idx}.png'))\n",
        "            plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxHpOMNdvoiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция тренировки модели\n",
        "def train(net, data_loader, n_epochs, lr, class_weights, verbose=0):\n",
        "    net.to(net.device)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
        "    loss_func = nn.CrossEntropyLoss(1.0 / class_weights).to(net.device)\n",
        "\n",
        "    training_time = time.time()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        epoch_time = time.time()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        processed = 0\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            image_batch = Variable(X_batch).to(net.device)\n",
        "            mask_batch = Variable(y_batch).to(net.device)\n",
        "\n",
        "            output_batch, softmaxed = net(image_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_func(output_batch, mask_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.float()\n",
        "            processed += data_loader.batch_size\n",
        "            processed_percent = round(\n",
        "                100.0 * processed / (len(data_loader) * data_loader.batch_size), \n",
        "                ndigits=3\n",
        "            )\n",
        "            if verbose == 2:\n",
        "                print(f\"Эпоха {epoch}: {processed_percent}%,\"\n",
        "                    f\"loss: {round_tensor(train_loss / processed, 5)}\")\n",
        "                \n",
        "        epoch_time = time.time() - epoch_time\n",
        "        if verbose:\n",
        "            print(f\"Окончание эпохи. Эпоха: {epoch}, \"\n",
        "                  f\"train_loss: {round_tensor(train_loss / processed, 5)}; {epoch_time} сек.; \"\n",
        "                  f\"Сохранение...\")\n",
        "        \n",
        "        with open(f'{net.name}.pth', 'w'):\n",
        "            torch.save(net.state_dict(), f\"{net.name}.pth\")\n",
        "\n",
        "    print(f\"Время обучения: {time.time() - training_time} сек.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H1RYwbbwkLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция предсказания\n",
        "def predict(net, data_loader, class_weights, save_prediction_images=False):\n",
        "    with torch.no_grad():\n",
        "        loss_func = nn.CrossEntropyLoss(1.0 / class_weights).to(net.device)\n",
        "\n",
        "        # Отслеживаемые метрики\n",
        "        accs = []\n",
        "        dices = []\n",
        "        losses = []\n",
        "\n",
        "        batch_id = 0\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            image_batch = Variable(X_batch).to(net.device)\n",
        "            mask_batch = Variable(y_batch).to(net.device)\n",
        "\n",
        "            output_batch, softmaxed = net(image_batch)\n",
        "            loss = loss_func(output_batch.squeeze(), mask_batch)\n",
        "\n",
        "            if save_prediction_images:\n",
        "                save_results(softmaxed, image_batch, mask_batch, \n",
        "                            path=Config.OUTPUT_DIR, name=f'batch:{batch_id}')\n",
        "            \n",
        "            accs.append(pixel_accuracy(mask_batch, softmaxed.argmax(axis=1)))\n",
        "            dices.append(dice_coefficient(mask_batch, softmaxed.argmax(axis=1)))\n",
        "            losses.append(loss)\n",
        "            \n",
        "            batch_id += 1\n",
        "            \n",
        "    return np.mean(accs), np.mean(dices), np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QUGuprWvpW0",
        "colab_type": "text"
      },
      "source": [
        "### Набор данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2RWX18Cv8Sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Класс-датасет\n",
        "class CocoPersons_Segmentation(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset_dir, train=True):\n",
        "        super(CocoPersons_Segmentation, self).__init__()\n",
        "\n",
        "        set_ = 'train/' if train else 'test/'\n",
        "        self.images_dir = os.path.join(dataset_dir, set_ , 'images/')\n",
        "        self.masks_dir = os.path.join(dataset_dir, set_, 'masks/')\n",
        "\n",
        "        self.masks_files = os.listdir(self.masks_dir)\n",
        "        self.file_names = [mask.split('_')[-1].split('.')[0] for mask in self.masks_files]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.file_names[idx]\n",
        "        mask_path = os.path.join(self.masks_dir, 'seg_' + name + '.png')\n",
        "        image_path = os.path.join(self.images_dir, name + '.jpg')\n",
        "\n",
        "        image = torch.FloatTensor(self.__load_image(image_path))\n",
        "        mask = torch.LongTensor(self.__load_mask(mask_path))\n",
        "        return image, mask\n",
        "\n",
        "    def __load_image(self, path):\n",
        "        img = np.array(Image.open(path).resize((Config.WIDTH, Config.HEIGHT)))\n",
        "\n",
        "        try:\n",
        "            image = img.transpose((2, 0, 1))\n",
        "        except ValueError:\n",
        "            image = gray2rgb(img).transpose((2, 0, 1))\n",
        "\n",
        "        image = np.array(image, dtype=np.float32) / 255.0\n",
        "        return image\n",
        "\n",
        "    def __load_mask(self, path):\n",
        "        mask = Image.open(path).resize((Config.WIDTH, Config.HEIGHT))\n",
        "        mask = np.array(mask, dtype=np.uint8) / 255.0\n",
        "        return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoBhHqTwFtk",
        "colab_type": "text"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVD1yWPPz5GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Выбираем параметры тренировки\n",
        "train_options = Config.get_option(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLYbRG71zoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Создаем объект-DataLoader на тренировочных данных\n",
        "coco_train_set = CocoPersons_Segmentation(dataset_dir=Config.DATA_DIR, train=True)\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    coco_train_set,\n",
        "    batch_size=train_options['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtIrNnuOwLJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Создаем и строим модель\n",
        "model = SegNet(input_channels=3, output_channels=Config.NUM_CLASSES, name='bin_SegNet0')\n",
        "\n",
        "# Запускаем тренировку модели\n",
        "train(\n",
        "    model, \n",
        "    data_loader=train_loader, \n",
        "    n_epochs=train_options['n_epochs'],\n",
        "    lr=train_options['lr'], \n",
        "    class_weights=Config.TRAIN_CLASS_PROBS,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjpGIqzElCPj",
        "colab_type": "text"
      },
      "source": [
        "### Предсказание не тренировочных данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XuDx_O-lGc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Загружаем натренированную модель\n",
        "model = SegNet(input_channels=3, output_channels=Config.NUM_CLASSES)\n",
        "model.load('bin_SegNet0.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m362BGclIit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "outputId": "0697374f-4472-4360-fbc0-b1c3b8eafeca"
      },
      "source": [
        "# Строим предсказание\n",
        "accuracy, dice_coef, ce_loss = predict(\n",
        "    model,\n",
        "    train_loader,\n",
        "    class_weights=Config.TEST_CLASS_PROBS\n",
        ")\n",
        "print(f\"Train Accuracy: {accuracy}, Train Dice coefficient: {dice_coef}, CE loss: {ce_loss}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8e74ff3240>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8e74ff3240>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8e74ff3240>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f8e74ff3240>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-720b2e60dc1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST_CLASS_PROBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Accuracy: {accuracy}, Train Dice coefficient: {dice_coef}, CE loss: {ce_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5ca4d2bc77a2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(net, data_loader, class_weights, save_prediction_images)\u001b[0m\n\u001b[1;32m     20\u001b[0m                             path=Config.OUTPUT_DIR, name=f'batch:{batch_id}')\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mdices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmaxed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4wy_KyxlgMW",
        "colab_type": "text"
      },
      "source": [
        "### Предсказание на тестовых данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpupcRxA1xMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Делаем похожие шаги\n",
        "test_options = Config.get_option(-1)\n",
        "\n",
        "coco_test_set = CocoPersons_Segmentation(dataset_dir=Config.DATA_DIR, train=False)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    coco_test_set,\n",
        "    batch_size=test_options['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAx4RjQbUyRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Строим предсказание\n",
        "accuracy, dice_coef = predict(\n",
        "    model,\n",
        "    test_loader,\n",
        "    class_weights=Config.TEST_CLASS_PROBS,\n",
        "    save_prediction_images=False\n",
        ")\n",
        "print(f\"Test Accuracy: {accuracy}, Test Dice coefficient: {dice_coef}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF4aDz8GS-jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}